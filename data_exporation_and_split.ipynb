{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6042bdf8",
   "metadata": {},
   "source": [
    "# Data Exploration & Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69c8f3",
   "metadata": {},
   "source": [
    "**Summary:** The purpose of this notebook is to dive deeper into the processing-blocks-master code created by Edge Impulse. Specifically this notebook examines what the data looks like before processing, during processing, and final expected outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a084b",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b512cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import sys, os\n",
    "import pathlib\n",
    "import base64\n",
    "import shutil\n",
    "from IPython.display import SVG\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "from scipy.io.wavfile import WavFileWarning\n",
    "warnings.simplefilter(\"ignore\", WavFileWarning)\n",
    "\n",
    "# process_data script\n",
    "ROOT = pathlib.Path('/home/bukowskin/CSC_7901_ML_Capstone')\n",
    "PROCESS_PATH = ROOT / 'functions' \n",
    "sys.path.append(str(PROCESS_PATH))\n",
    "from process_data import Process_Audio_Data\n",
    "\n",
    "# speechpy functions\n",
    "SPEECHPY_PATH =  ROOT / 'functions' / 'edge-impulse-functions' / 'third_party'/ 'speechpy'/'__init__.py' \n",
    "MODULE_NAME = 'speechpy'\n",
    "import importlib\n",
    "spec = importlib.util.spec_from_file_location(MODULE_NAME, SPEECHPY_PATH)\n",
    "speechpy = importlib.util.module_from_spec(spec)\n",
    "sys.modules[spec.name] = speechpy\n",
    "spec.loader.exec_module(speechpy)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf3b42",
   "metadata": {},
   "source": [
    "## Path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/bukowskin/CSC_7901_ML_Capstone/data/all_data/' # original, not split or processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3539dd",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd41100",
   "metadata": {},
   "source": [
    "### Single File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_audio_sample = f'{data_path}/two.noise_0.female.iphone.SZQlO4oFWd.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq, raw_data = wavfile.read(single_audio_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=single_audio_sample, rate=sampling_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664791dd",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_spectrum(frames, fft_points=512):\n",
    "    \"\"\"This function computes the one-dimensional n-point discrete Fourier\n",
    "    Transform (DFT) of a real-valued array by means of an efficient algorithm\n",
    "    called the Fast Fourier Transform (FFT). Please refer to\n",
    "    https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.rfft.html\n",
    "    for further details.\n",
    "        NOTE: Taken function from functions/edge-impulse-functions/third-party/speechpy/processing\n",
    "    Args:\n",
    "        frames (array): The frame array in which each row is a frame.\n",
    "        fft_points (int): The length of FFT. If fft_length is greater than frame_len, the frames will be zero-padded.\n",
    "\n",
    "    Returns:\n",
    "            array: The fft spectrum.\n",
    "            If frames is an num_frames x sample_per_frame matrix, output\n",
    "            will be num_frames x FFT_LENGTH.\n",
    "    \"\"\"\n",
    "    SPECTRUM_VECTOR = np.fft.rfft(frames, n=fft_points, axis=-1, norm=None)\n",
    "    return np.absolute(SPECTRUM_VECTOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59563ebc",
   "metadata": {},
   "source": [
    "### Raw Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating time axis\n",
    "duration = len(raw_data) / sampling_freq\n",
    "time_axis = np.linspace(0, duration, num=len(raw_data))\n",
    "\n",
    "# Plotting raw audio signal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_axis, raw_data, color='blue')\n",
    "plt.title(f'Raw Audio Signal - Unique ID: 2eDgHfQz2u')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5839bc1",
   "metadata": {},
   "source": [
    "### FFT-Spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39234d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.reshape(int(len(raw_data) / len(['accY'])), len(['accY']))\n",
    "\n",
    "features = []\n",
    "graphs = []\n",
    "\n",
    "for ax in range(0, len(['accY'])):\n",
    "    signal = raw_data[:,ax]\n",
    "\n",
    "    numframes, _, __ = speechpy.processing.calculate_number_of_frames(\n",
    "        signal,\n",
    "        implementation_version=4,\n",
    "        sampling_frequency=sampling_freq,\n",
    "        frame_length= 0.02,\n",
    "        frame_stride= 0.02,\n",
    "        zero_padding=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c11704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack frames\n",
    "frames = speechpy.processing.stack_frames(\n",
    "    signal,\n",
    "    implementation_version=4,\n",
    "    sampling_frequency=sampling_freq,\n",
    "    frame_length=0.02,\n",
    "    frame_stride=0.02,\n",
    "    filter=lambda x: np.ones(\n",
    "        (x,\n",
    "         )),\n",
    "    zero_padding=False)\n",
    "# Note: code segment taking from process_data script, initial step required to run fft_spectrogram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_spectrogram = fft_spectrum(frames,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85daaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(fft_spectrogram.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(label='Spectrogram Amplitude')\n",
    "plt.title('FFT-Spectrogram - Unique ID: 2eDgHfQz2u')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60e63f",
   "metadata": {},
   "source": [
    "### MFE-Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 40\n",
    "fft_length = 256\n",
    "noise_floor_db = -52\n",
    "window_size = 0.1\n",
    "path = '/home/bukowskin/CSC_7901_ML_Capstone/data/all_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e21198",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_mel_40 = Process_Audio_Data(path,\n",
    "                                       True, # create mfe graphs\n",
    "                                       n_mels, # number of filters\n",
    "                                       fft_length,\n",
    "                                       noise_floor_db,\n",
    "                                       window_size,\n",
    "                                       0) # low freqeuncy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2072a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_mel_40.generate_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254fbb1",
   "metadata": {},
   "source": [
    "#### MFE Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_mel_40.mfe_graphs['SZQlO4oFWd']\n",
    "image = image[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a90b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_image = base64.b64decode(image)\n",
    "svg_string = decoded_image.decode('utf-8')\n",
    "SVG(svg_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8af565",
   "metadata": {},
   "source": [
    "#### MFCC Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_mel_40.mfcc_graphs['SZQlO4oFWd']\n",
    "image = image[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c489eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_image = base64.b64decode(image)\n",
    "svg_string = decoded_image.decode('utf-8')\n",
    "plt.title('MFCC-Spectrogram - Unique ID: 2eDgHfQz2u')\n",
    "SVG(svg_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac67e2",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98853f",
   "metadata": {},
   "source": [
    "Applying split for training and testing and save it into corresponding folders that can be easily loaded and maintain a similar train/test split throughout. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3398bb",
   "metadata": {},
   "source": [
    "### Parse Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710876c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = []\n",
    "for filename in os.listdir(data_path):\n",
    "    file_parts = filename.split(\".\")\n",
    "    parsed_data.append({\n",
    "        \"file_name\": filename,\n",
    "        \"label\": file_parts[0],\n",
    "        \"noise_type\": file_parts[1],\n",
    "        \"gender\": file_parts[2],\n",
    "        \"device\": file_parts[3],\n",
    "        \"id\": file_parts[4]\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(parsed_data)\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbf5aa",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"groups\"] = df[\"label\"] + \".\" + df[\"noise_type\"] + \".\" + df[\"gender\"] + \".\" + df[\"device\"]\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df[\"groups\"], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8d79a",
   "metadata": {},
   "source": [
    "### Save Train/Test Split Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/bukowskin/CSC_7901_ML_Capstone/data'\n",
    "\n",
    "# each unique directories name for saving raw data after each split\n",
    "data_save_path = {\n",
    "    42: f'{base_path}/data_split_random_state_42',\n",
    "    73: f'{base_path}/data_split_random_state_73',\n",
    "    13: f'{base_path}/data_split_random_state_13'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6412a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_files(df, destination_dir):\n",
    "    for index, row in df.iterrows():\n",
    "        source_file = os.path.join(data_path, row[\"file_name\"])\n",
    "        destin_file = os.path.join(destination_dir, row[\"file_name\"])\n",
    "\n",
    "        shutil.copy(source_file, destin_file)  # copying file to new path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_split_files(train, f'{data_save_path[random_state]}/raw_data_split/train/')\n",
    "save_split_files(test, f'{data_save_path[random_state]}/raw_data_split/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c6602a",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ff6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Process Parameters\n",
    "n_mels = 58\n",
    "fft_length = 256\n",
    "noise_floor_db = -52\n",
    "window_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa73522",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = f'{data_save_path[random_state]}/raw_data_split/train/'\n",
    "preprocess_train = Process_Audio_Data(train_data_path,\n",
    "                                       True, # create mfe graphs\n",
    "                                       n_mels, # number of filters\n",
    "                                       fft_length,\n",
    "                                       noise_floor_db,\n",
    "                                       window_size,\n",
    "                                       0) # low freqeuncy\n",
    "\n",
    "# Generating MFE and MFCC features from edited Edge Impulse Processing Block code [2]\n",
    "preprocess_train.generate_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76491a",
   "metadata": {},
   "source": [
    "#### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = f'{data_save_path[random_state]}/raw_data_split/test/'\n",
    "preprocess_test = Process_Audio_Data(test_data_path,\n",
    "                                       True, # create mfe graphs\n",
    "                                       n_mels, # number of filters\n",
    "                                       fft_length,\n",
    "                                       noise_floor_db,\n",
    "                                       window_size,\n",
    "                                       0) # low freqeuncy\n",
    "\n",
    "# Generating MFE and MFCC features from edited Edge Impulse Processing Block code [2]\n",
    "preprocess_test.generate_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f32a97",
   "metadata": {},
   "source": [
    "### Save Train/Test Split Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_feats(save_path, num_mel, split_type, feat_type, preprocess):\n",
    "    '''\n",
    "    Saving generated features\n",
    "    '''\n",
    "    if feat_type == 'mfe':\n",
    "        save_data = {\n",
    "            'features': preprocess.mfe_features,\n",
    "            'labels': preprocess.data_info['label'].reset_index(drop=True).values,\n",
    "            'mfe_height': preprocess.mfe_height,\n",
    "            'mfe_width': preprocess.mfe_width,\n",
    "        }\n",
    "    else:\n",
    "        save_data = {\n",
    "            'features': preprocess.mfcc_features,\n",
    "            'labels': preprocess.data_info['label'].reset_index(drop=True).values,\n",
    "            'mfe_height': preprocess.mfcc_height,\n",
    "            'mfe_width': preprocess.mfcc_width,\n",
    "        }\n",
    "    with open(f'{save_path}/number_mel_filters_{num_mel}/{feat_type}_data_split/{split_type}_data.pkl', 'wb') as f:\n",
    "        pickle.dump(save_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFE\n",
    "save_generated_feats(data_save_path[random_state], n_mels,'train', 'mfe', preprocess_test)\n",
    "save_generated_feats(data_save_path[random_state], n_mels,'test', 'mfe', preprocess_test)\n",
    "\n",
    "# MFCC\n",
    "save_generated_feats(data_save_path[random_state],n_mels,'train', 'mfcc', preprocess_test)\n",
    "save_generated_feats(data_save_path[random_state],n_mels,'test', 'mfcc', preprocess_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db187d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
